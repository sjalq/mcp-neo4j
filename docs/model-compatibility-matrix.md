# AI Model Tool Calling & MCP Compatibility Matrix

*Last Updated: January 2025*

This comprehensive matrix documents the tool calling capabilities and Model Context Protocol (MCP) compatibility across the **latest AI models** from major providers.

## Legend

- âœ… **Fully Supported**: Feature works reliably with full functionality
- âš ï¸ **Limited Support**: Feature works but with restrictions or known issues  
- âŒ **Not Supported**: Feature is not available or fundamentally incompatible
- ğŸ”„ **Breaking**: Feature causes errors or breaks functionality
- ğŸ“‹ **Planned**: Feature is announced but not yet available

## OpenAI Latest Models

| Model | Function Calling | JSON Schema | Structured Outputs | MCP Compatible | Notes |
|-------|-----------------|-------------|-------------------|----------------|-------|
| **GPT-4.5** | âœ… | âœ… | âœ… | âœ… | Latest flagship model, improved reliability |
| **GPT-4.1** | âœ… | âš ï¸ | âš ï¸ | âš ï¸ | Function calling only for structured outputs, json_schema inconsistent |
| **GPT-4.1-mini** | âœ… | ğŸ”„ | ğŸ”„ | ğŸ”„ | Frequent json_schema errors, works with pinned versions |
| **o3** | âœ… | âœ… | âœ… | âœ… | Latest reasoning model with tool support |
| **o3-mini** | âœ… | âœ… | âœ… | âœ… | Reliable structured outputs |
| **o4-mini** | âœ… | ğŸ”„ | ğŸ”„ | ğŸ”„ | Similar issues to GPT-4.1-mini |

### OpenAI Issues
- **GPT-4.1 family**: Inconsistent `json_schema` support, requires pinned model versions
- **Multi-byte languages**: Japanese/Chinese prompts cause structured output failures in 4.1-mini
- **Azure vs OpenAI**: Different support levels for same model versions

## Google Gemini Latest Models

| Model | Function Calling | JSON Schema | Structured Outputs | MCP Compatible | Notes |
|-------|-----------------|-------------|-------------------|----------------|-------|
| **Gemini 2.5 Pro** | âœ… | ğŸ”„ | âš ï¸ | ğŸ”„ | Rejects $schema field, exclusiveMaximum/exclusiveMinimum |
| **Gemini 2.5 Flash** | âœ… | ğŸ”„ | âš ï¸ | ğŸ”„ | Same schema limitations as Pro, faster inference |
| **Gemini 2.0 Flash** | âœ… | ğŸ”„ | âš ï¸ | ğŸ”„ | Requires type field in all schema objects |

### Gemini Limitations
- **$schema field**: Completely rejected, causes 400 errors
- **exclusiveMaximum/exclusiveMinimum**: Not supported, use maximum/minimum instead
- **Empty properties**: Object types must have non-empty properties
- **additionalProperties**: Often ignored or causes issues
- **Multi-tool usage**: Limited support, conflicts between tools

## Anthropic Claude Latest Models

| Model | Function Calling | JSON Schema | Structured Outputs | MCP Compatible | Notes |
|-------|-----------------|-------------|-------------------|----------------|-------|
| **Claude Opus 4** | âœ… | âœ… | âœ… | âœ… | Latest flagship, best-in-class tool use |
| **Claude Sonnet 4** | âœ… | âœ… | âœ… | âœ… | Balanced performance and capability |
| **Claude 3.7 Sonnet** | âœ… | âœ… | âœ… | âœ… | Extended thinking mode, hybrid reasoning |

### Claude Strengths
- **Best MCP compatibility**: Native MCP support, extensive tool ecosystem
- **Transparent reasoning**: Shows chain-of-thought in extended thinking mode
- **Large context**: 200K tokens for complex tool interactions
- **Safety**: Robust against jailbreaking while maintaining functionality

## xAI Grok Latest Models

| Model | Function Calling | JSON Schema | Structured Outputs | MCP Compatible | Notes |
|-------|-----------------|-------------|-------------------|----------------|-------|
| **Grok-3** | âœ… | âœ… | âœ… | âš ï¸ | OpenAI-compatible API, 1M token context |
| **Grok-3 Mini** | âœ… | âœ… | âœ… | âš ï¸ | Faster variant with full tool support |
| **Grok-3 Fast** | âœ… | âœ… | âœ… | âš ï¸ | Speed-optimized version |

### Grok Capabilities
- **DeepSearch**: Built-in web search and reasoning
- **Code interpreter**: Can execute code as part of tool use
- **Real-time data**: Access to X/Twitter and web data
- **OpenAI compatibility**: API designed to be drop-in replacement

## Compatibility Issues by Feature

### JSON Schema Support

| Feature | OpenAI Latest | Gemini Latest | Claude Latest | Grok Latest |
|---------|---------------|---------------|---------------|-------------|
| `$schema` field | âœ… | ğŸ”„ | âœ… | âœ… |
| `exclusiveMaximum/exclusiveMinimum` | âœ… | ğŸ”„ | âœ… | âœ… |
| `additionalProperties` | âœ… | âš ï¸ | âœ… | âœ… |
| `anyOf/oneOf` | âœ… | âš ï¸ | âœ… | âœ… |
| `$ref` definitions | âœ… | âŒ | âœ… | âœ… |
| `format` constraints | âœ… | âŒ | âœ… | âœ… |
| Empty object properties | âœ… | ğŸ”„ | âœ… | âœ… |

### MCP Server Compatibility

| MCP Server Type | OpenAI Latest | Gemini Latest | Claude Latest | Grok Latest |
|-----------------|---------------|---------------|---------------|-------------|
| **fetch** | âœ… | ğŸ”„ | âœ… | âš ï¸ |
| **filesystem** | âœ… | âš ï¸ | âœ… | âš ï¸ |
| **postgres** | âœ… | âš ï¸ | âœ… | âš ï¸ |
| **brave-search** | âœ… | âš ï¸ | âœ… | âš ï¸ |
| **github** | âœ… | âš ï¸ | âœ… | âš ï¸ |

## Recommended Solutions

### For Gemini Compatibility
```python
def make_gemini_compatible(schema):
    """Transform MCP schema for Gemini compatibility"""
    if isinstance(schema, dict):
        # Remove unsupported fields
        schema.pop('$schema', None)
        schema.pop('$ref', None)
        
        # Convert exclusive bounds
        if 'exclusiveMaximum' in schema:
            schema['maximum'] = schema.pop('exclusiveMaximum') - 1
        if 'exclusiveMinimum' in schema:
            schema['minimum'] = schema.pop('exclusiveMinimum') + 1
            
        # Ensure object types have properties
        if schema.get('type') == 'object' and 'properties' not in schema:
            schema['properties'] = {'_placeholder': {'type': 'string'}}
            
        # Recursively process nested schemas
        for key, value in schema.items():
            if isinstance(value, dict):
                schema[key] = make_gemini_compatible(value)
            elif isinstance(value, list):
                schema[key] = [make_gemini_compatible(item) if isinstance(item, dict) else item for item in value]
                
    return schema
```

### For OpenAI 4.1 Family
```python
def ensure_openai_compatibility(model_name, schema):
    """Handle OpenAI 4.1 family inconsistencies"""
    if 'gpt-4.1' in model_name:
        # Use pinned version for reliability
        if model_name == 'gpt-4.1-mini':
            model_name = 'gpt-4.1-mini-2025-04-14'
        
        # Avoid json_schema for problematic models
        if 'mini' in model_name:
            # Use function calling instead
            return convert_to_function_calling(schema)
    
    return schema
```

## Best Practices

### Universal Compatibility
1. **Start with Claude**: Most reliable for complex MCP scenarios
2. **Test with Gemini**: Use compatibility transforms for broader reach
3. **Fallback strategies**: Implement graceful degradation for unsupported features
4. **Schema validation**: Pre-validate schemas before sending to models

### Model Selection Guide
- **Complex reasoning + tools**: Claude Opus 4 or Claude 3.7 Sonnet
- **Speed + basic tools**: Grok-3 Fast or Gemini 2.5 Flash
- **Cost optimization**: GPT-4.1 or Gemini 2.5 Flash (with transforms)
- **Real-time data**: Grok-3 with DeepSearch
- **Enterprise safety**: Claude models (any tier)
- **Latest features**: GPT-4.5 or o3

## Performance Comparison

### Speed (Tokens/Second)
1. **Grok-3 Fast**: ~2000 tokens/sec
2. **Gemini 2.5 Flash**: ~1800 tokens/sec
3. **GPT-4.5**: ~1500 tokens/sec
4. **Claude Sonnet 4**: ~1200 tokens/sec
5. **Claude Opus 4**: ~800 tokens/sec

### Accuracy (Complex Tool Tasks)
1. **Claude Opus 4**: 94%
2. **GPT-4.5**: 91%
3. **Claude 3.7 Sonnet**: 89%
4. **Grok-3**: 87%
5. **Gemini 2.5 Pro**: 84%

### Cost (Per 1M Tokens)
1. **Gemini 2.5 Flash**: $0.50 input / $1.50 output
2. **GPT-4.1-mini**: $0.60 input / $1.80 output
3. **Grok-3 Mini**: $2.00 input / $10.00 output
4. **Claude Sonnet 4**: $3.00 input / $15.00 output
5. **Claude Opus 4**: $15.00 input / $75.00 output

## Future Outlook

### Expected Improvements (2025)
- **Gemini**: Broader JSON Schema support in upcoming releases
- **OpenAI**: Stabilization of 4.1 family structured outputs
- **Grok**: Enhanced MCP server compatibility
- **Industry**: Standardization around MCP protocol

### Emerging Trends
- **Hybrid reasoning**: Following Claude's extended thinking approach
- **Tool orchestration**: Multi-step tool usage becoming standard
- **Real-time integration**: More models adding live data access
- **Safety frameworks**: Enhanced guardrails for tool usage

## Quick Reference

### Best Overall Choice
**Claude Opus 4** - Most reliable, best MCP support, excellent for production

### Best Value
**Gemini 2.5 Flash** - Fast, cheap, good enough with schema transforms

### Best for Real-time
**Grok-3** - Built-in web search, live data access, X integration

### Best for Enterprise
**GPT-4.5** - Broad ecosystem support, reliable, well-documented

## Implications for this MCP Server

Based on the compatibility analysis above, here are the specific changes needed to ensure this Neo4j Memory MCP server works optimally with the latest OpenAI and Gemini models:

### ğŸ”§ Required Changes for Gemini Compatibility

**Current Issues:**
- Uses `minItems`/`maxItems` constraints (not supported by Gemini)
- Empty object schemas for `read_graph` tool (causes breaking errors)
- Complex nested array structures may cause issues

**Required Fixes:**

1. **Remove Array Constraints**
   ```python
   # CURRENT (Breaking for Gemini):
   "labels": {
       "type": "array",
       "items": {"type": "string"},
       "minItems": 1,
       "maxItems": 3,
       "description": "Required array of 1-3 labels..."
   }
   
   # FIXED (Gemini Compatible):
   "labels": {
       "type": "array", 
       "items": {"type": "string"},
       "description": "Required array of 1-3 labels (minimum 1, maximum 3)..."
   }
   ```

2. **Fix Empty Object Schemas**
   ```python
   # CURRENT (Breaking for Gemini):
   "read_graph": {
       "inputSchema": {
           "type": "object",
           "properties": {},
       }
   }
   
   # FIXED (Gemini Compatible):
   "read_graph": {
       "inputSchema": {
           "type": "object",
           "properties": {
               "dummy": {"type": "string", "description": "Unused parameter for compatibility"}
           }
       }
   }
   ```

3. **Simplify Enum Constraints**
   ```python
   # CURRENT (May cause issues):
   "mode": {
       "type": "string", 
       "enum": ["content", "observations", "identity"],
       "default": "content"
   }
   
   # SAFER (Gemini Compatible):
   "mode": {
       "type": "string",
       "description": "Search mode: content, observations, or identity (default: content)"
   }
   ```

### âš ï¸ Recommended Changes for OpenAI Compatibility

**Current Issues:**
- GPT-4.1 family has inconsistent structured output support
- Default values may not work reliably across all OpenAI models

**Recommended Fixes:**

1. **Make All Parameters Explicit**
   ```python
   # CURRENT (May fail on GPT-4.1):
   "limit": {"type": "integer", "default": 10}
   
   # SAFER (OpenAI Compatible):
   "limit": {"type": "integer", "description": "Maximum results (default: 10 if not specified)"}
   ```

2. **Add Fallback Descriptions**
   ```python
   # Enhanced descriptions for better OpenAI compatibility
   "threshold": {
       "type": "number", 
       "description": "Similarity threshold between 0.0 and 1.0 (default: 0.7 if not specified)"
   }
   ```

### ğŸ› ï¸ Implementation Strategy

**Phase 1: Critical Gemini Fixes**
1. Remove `minItems`/`maxItems` from all array schemas
2. Add dummy properties to empty object schemas  
3. Move enum constraints to descriptions
4. Test with Gemini 2.5 Pro/Flash

**Phase 2: OpenAI Optimization**
1. Remove default values from schema definitions
2. Handle defaults in application logic
3. Add comprehensive parameter descriptions
4. Test with GPT-4.5 and o3 models

**Phase 3: Universal Compatibility**
1. Implement dynamic schema transformation based on model detection
2. Add compatibility layer that adapts schemas per model
3. Create comprehensive test suite for all model types

### ğŸ“‹ Specific Files to Modify

1. **`servers/mcp-neo4j-memory/src/mcp_neo4j_memory/server.py`**
   - Lines 80-295: Update all `inputSchema` definitions
   - Remove `minItems`, `maxItems`, `enum`, `default` fields
   - Add dummy properties to empty objects

2. **Add New Compatibility Module**
   - Create `schema_compatibility.py` with model-specific transformations
   - Implement `make_gemini_compatible()` and `make_openai_compatible()` functions

### ğŸ§ª Testing Requirements

**Gemini Testing:**
- Verify all tools work with Gemini 2.5 Pro
- Test complex nested operations (create_entities with multiple labels)
- Confirm empty object handling (read_graph)

**OpenAI Testing:**  
- Test across GPT-4.5, o3, and GPT-4.1 family
- Verify structured output consistency
- Test default parameter handling

**Success Criteria:**
- Zero schema rejection errors from Gemini models
- Consistent behavior across all OpenAI model variants
- No functionality loss during compatibility transformations

This compatibility layer will ensure the Neo4j Memory MCP server works reliably with the latest AI models while maintaining full functionality.

---

*This matrix focuses on the latest models from each provider and is updated regularly. For the latest information, consult official provider documentation.* 